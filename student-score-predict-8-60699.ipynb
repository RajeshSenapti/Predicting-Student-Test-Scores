{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":119082,"databundleVersionId":14993753,"sourceType":"competition"},{"sourceId":10909264,"sourceType":"datasetVersion","datasetId":6780703},{"sourceId":13904981,"sourceType":"datasetVersion","datasetId":8762382}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import TargetEncoder\nfrom sklearn.linear_model import LassoCV, ElasticNetCV\nfrom category_encoders import TargetEncoder\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nnp.random.seed(42)\n\ntrain_df = pd.read_csv(\"/kaggle/input/playground-series-s6e1/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/playground-series-s6e1/test.csv\")\noriginal_df = pd.read_csv(\"/kaggle/input/exam-score-prediction-dataset/Exam_Score_Prediction.csv\")\noriginal_df2 = pd.read_csv(\"/kaggle/input/student-performance-prediction/student_performance_dataset.csv\")\n\nsubmission_df = pd.read_csv(\"/kaggle/input/playground-series-s6e1/sample_submission.csv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-01T14:58:52.004226Z","iopub.execute_input":"2026-02-01T14:58:52.004950Z","iopub.status.idle":"2026-02-01T14:58:53.397204Z","shell.execute_reply.started":"2026-02-01T14:58:52.004892Z","shell.execute_reply":"2026-02-01T14:58:53.396189Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(f\"Train shape:    {train_df.shape}\")\nprint(f\"Test shape:     {test_df.shape}\")\nprint(f\"Original shape: {original_df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T14:58:53.398741Z","iopub.execute_input":"2026-02-01T14:58:53.399155Z","iopub.status.idle":"2026-02-01T14:58:53.404854Z","shell.execute_reply.started":"2026-02-01T14:58:53.399125Z","shell.execute_reply":"2026-02-01T14:58:53.403993Z"}},"outputs":[{"name":"stdout","text":"Train shape:    (630000, 13)\nTest shape:     (270000, 12)\nOriginal shape: (20000, 13)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"TARGET = \"exam_score\"\nID_COL = \"id\"\n\nbase_features = [col for col in train_df.columns if col not in [TARGET, ID_COL]]\nCATS = train_df.select_dtypes(\"object\").columns.to_list()\n\nprint(f\"\\nBase features: {len(base_features)}\")\nprint(f\"Categorical features: {CATS}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T14:58:53.406014Z","iopub.execute_input":"2026-02-01T14:58:53.406329Z","iopub.status.idle":"2026-02-01T14:58:53.463784Z","shell.execute_reply.started":"2026-02-01T14:58:53.406300Z","shell.execute_reply":"2026-02-01T14:58:53.462769Z"}},"outputs":[{"name":"stdout","text":"\nBase features: 11\nCategorical features: ['gender', 'course', 'internet_access', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def preprocess_optimized(df):\n    \"\"\"\n    Generate high-value features INCLUDING binned features.\n    Returns: (DataFrame with selected features, list of numeric feature names)\n    \"\"\"\n    df_temp = df.copy()\n    eps = 1e-5\n\n    # Polynomials (2nd order only)\n    df_temp['study_hours_squared'] = df_temp['study_hours'] ** 2\n    df_temp['class_attendance_squared'] = df_temp['class_attendance'] ** 2\n    df_temp['sleep_hours_squared'] = df_temp['sleep_hours'] ** 2\n    df_temp['age_squared'] = df_temp['age'] ** 2\n\n    # Log transforms\n    sh_pos = df_temp['study_hours'].clip(lower=0)\n    ca_pos = df_temp['class_attendance'].clip(lower=0)\n    sl_pos = df_temp['sleep_hours'].clip(lower=0)\n\n    df_temp['log_study_hours'] = np.log1p(sh_pos)\n    df_temp['log_class_attendance'] = np.log1p(ca_pos)\n    df_temp['log_sleep_hours'] = np.log1p(sl_pos)\n\n    # Sqrt transforms\n    df_temp['sqrt_study_hours'] = np.sqrt(sh_pos)\n    df_temp['sqrt_class_attendance'] = np.sqrt(ca_pos)\n\n    # Key interactions\n    df_temp['study_hours_times_attendance'] = df_temp['study_hours'] * df_temp['class_attendance']\n    df_temp['study_hours_times_sleep'] = df_temp['study_hours'] * df_temp['sleep_hours']\n    df_temp['attendance_times_sleep'] = df_temp['class_attendance'] * df_temp['sleep_hours']\n    df_temp['age_times_study_hours'] = df_temp['age'] * df_temp['study_hours']\n\n    # Important ratios\n    df_temp['study_hours_over_sleep'] = df_temp['study_hours'] / (df_temp['sleep_hours'] + eps)\n    df_temp['attendance_over_sleep'] = df_temp['class_attendance'] / (df_temp['sleep_hours'] + eps)\n    df_temp['attendance_over_study'] = df_temp['class_attendance'] / (df_temp['study_hours'] + eps)\n\n    # Ordinal encoding\n    sleep_quality_map = {'poor': 0, 'average': 1, 'good': 2}\n    facility_rating_map = {'low': 0, 'medium': 1, 'high': 2}\n    exam_difficulty_map = {'easy': 0, 'moderate': 1, 'hard': 2}\n\n    df_temp['sleep_quality_numeric'] = df_temp['sleep_quality'].map(sleep_quality_map).fillna(1).astype(int)\n    df_temp['facility_rating_numeric'] = df_temp['facility_rating'].map(facility_rating_map).fillna(1).astype(int)\n    df_temp['exam_difficulty_numeric'] = df_temp['exam_difficulty'].map(exam_difficulty_map).fillna(1).astype(int)\n\n    # Ordinal × numeric interactions\n    df_temp['study_hours_times_sleep_quality'] = df_temp['study_hours'] * df_temp['sleep_quality_numeric']\n    df_temp['attendance_times_facility'] = df_temp['class_attendance'] * df_temp['facility_rating_numeric']\n    df_temp['sleep_hours_times_difficulty'] = df_temp['sleep_hours'] * df_temp['exam_difficulty_numeric']\n\n    # Ordinal × ordinal interactions\n    df_temp['facility_x_sleepq'] = df_temp['facility_rating_numeric'] * df_temp['sleep_quality_numeric']\n    df_temp['difficulty_x_facility'] = df_temp['exam_difficulty_numeric'] * df_temp['facility_rating_numeric']\n\n    # Rule-based flags\n    df_temp[\"high_att_high_study\"] = ((df_temp[\"class_attendance\"] >= 90) & (df_temp[\"study_hours\"] >= 6)).astype(int)\n    df_temp[\"ideal_sleep_flag\"] = ((df_temp[\"sleep_hours\"] >= 7) & (df_temp[\"sleep_hours\"] <= 9)).astype(int)\n    df_temp[\"high_study_flag\"] = (df_temp[\"study_hours\"] >= 7).astype(int)\n\n    # Composite efficiency\n    df_temp['efficiency'] = (df_temp['study_hours'] * df_temp['class_attendance']) / (df_temp['sleep_hours'] + 1)\n\n    # Gap features\n    df_temp['sleep_gap_8'] = (df_temp['sleep_hours'] - 8.0).abs()\n    df_temp['attendance_gap_100'] = (df_temp['class_attendance'] - 100.0).abs()\n\n    # BINNED FEATURES (KEEP THESE - THEY ARE VALUABLE!)\n    df_temp['study_bin_num'] = pd.cut(df_temp['study_hours'], bins=5, labels=False).astype(int)\n    df_temp['attendance_bin_num'] = pd.cut(df_temp['class_attendance'], bins=5, labels=False).astype(int)\n    df_temp['sleep_bin_num'] = pd.cut(df_temp['sleep_hours'], bins=5, labels=False).astype(int)\n    df_temp['age_bin_num'] = pd.cut(df_temp['age'], bins=5, labels=False).astype(int)\n\n    # Feature list (34 features total)\n    numeric_features = [\n        'study_hours_squared', 'class_attendance_squared', 'sleep_hours_squared', 'age_squared',\n        'log_study_hours', 'log_class_attendance', 'log_sleep_hours',\n        'sqrt_study_hours', 'sqrt_class_attendance',\n        'study_hours_times_attendance', 'study_hours_times_sleep', 'attendance_times_sleep',\n        'age_times_study_hours',\n        'study_hours_over_sleep', 'attendance_over_sleep', 'attendance_over_study',\n        'sleep_quality_numeric', 'facility_rating_numeric', 'exam_difficulty_numeric',\n        'study_hours_times_sleep_quality', 'attendance_times_facility', 'sleep_hours_times_difficulty',\n        'facility_x_sleepq', 'difficulty_x_facility',\n        'high_att_high_study', 'ideal_sleep_flag', 'high_study_flag',\n        'efficiency',\n        'sleep_gap_8', 'attendance_gap_100',\n        'study_bin_num', 'attendance_bin_num', 'sleep_bin_num', 'age_bin_num'\n    ]\n\n    return df_temp[base_features + numeric_features], numeric_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T14:58:53.464976Z","iopub.execute_input":"2026-02-01T14:58:53.465324Z","iopub.status.idle":"2026-02-01T14:58:53.483004Z","shell.execute_reply.started":"2026-02-01T14:58:53.465298Z","shell.execute_reply":"2026-02-01T14:58:53.482024Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"X_raw, numeric_cols = preprocess_optimized(train_df)\ny = train_df[TARGET].reset_index(drop=True)\n\nX_test_raw, _ = preprocess_optimized(test_df)\nX_orig_raw, _ = preprocess_optimized(original_df)\ny_orig = original_df[TARGET].reset_index(drop=True)\n\nfull_data = pd.concat([X_raw, X_test_raw, X_orig_raw], axis=0, ignore_index=True)\n\nfor col in numeric_cols:\n    full_data[col] = full_data[col].astype(float)\n\nX = full_data.iloc[:len(train_df)].copy()\nX_test = full_data.iloc[len(train_df):len(train_df) + len(test_df)].copy()\nX_original = full_data.iloc[len(train_df) + len(test_df):].copy()\n\nprint(f\"Engineered features: {len(numeric_cols)}\")\nprint(f\"Total features: {X.shape[1]} (11 base + {len(numeric_cols)} engineered)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T14:58:53.485464Z","iopub.execute_input":"2026-02-01T14:58:53.486219Z","iopub.status.idle":"2026-02-01T14:58:55.323780Z","shell.execute_reply.started":"2026-02-01T14:58:53.486176Z","shell.execute_reply":"2026-02-01T14:58:55.322994Z"}},"outputs":[{"name":"stdout","text":"Engineered features: 34\nTotal features: 45 (11 base + 34 engineered)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"FOLDS = 10\ny_bins = pd.qcut(y, q=10, labels=False)\nkf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=1003)\n\noof_pred_lr = np.zeros(len(X))\noof_pred_lasso = np.zeros(len(X))\noof_pred_enet = np.zeros(len(X))\n\ntest_preds_lr = np.zeros((len(X_test), FOLDS))\ntest_preds_lasso = np.zeros((len(X_test), FOLDS))\ntest_preds_enet = np.zeros((len(X_test), FOLDS))\n\norig_preds_lr = np.zeros(len(X_original))\norig_preds_lasso = np.zeros(len(X_original))\norig_preds_enet = np.zeros(len(X_original))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T14:58:55.324808Z","iopub.execute_input":"2026-02-01T14:58:55.325201Z","iopub.status.idle":"2026-02-01T14:58:55.398702Z","shell.execute_reply.started":"2026-02-01T14:58:55.325174Z","shell.execute_reply":"2026-02-01T14:58:55.397547Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\n\nfor fold, (tr, val) in enumerate(kf.split(X, y_bins), 1):\n\n    X_tr, X_val = X.iloc[tr], X.iloc[val]\n    y_tr, y_val = y.iloc[tr], y.iloc[val]\n\n    X_tr_full = pd.concat([X_tr, X_original], axis=0, ignore_index=True)\n    y_tr_full = pd.concat([y_tr, y_orig], axis=0, ignore_index=True)\n\n    te = TargetEncoder()\n\n    X_tr_enc = X_tr_full.copy()\n    X_val_enc = X_val.copy()\n    X_test_enc = X_test.copy()\n\n    X_tr_enc[CATS] = te.fit_transform(X_tr_full[CATS], y_tr_full)\n    X_val_enc[CATS] = te.transform(X_val[CATS])\n    X_test_enc[CATS] = te.transform(X_test[CATS])\n\n    # Ridge\n    ridge = RidgeCV(alphas=np.logspace(-3, 3, 20), cv=5)\n    ridge.fit(X_tr_enc, y_tr_full)\n\n    oof_pred_lr[val] = ridge.predict(X_val_enc)\n    test_preds_lr[:, fold-1] = ridge.predict(X_test_enc)\n    orig_preds_lr += ridge.predict(\n        X_tr_enc.iloc[-len(X_original):]\n    ) / FOLDS\n\n    # Lasso\n    lasso = LassoCV(alphas=np.logspace(-4, 1, 30), cv=5, n_jobs=-1)\n    lasso.fit(X_tr_enc, y_tr_full)\n\n    oof_pred_lasso[val] = lasso.predict(X_val_enc)\n    test_preds_lasso[:, fold-1] = lasso.predict(X_test_enc)\n    orig_preds_lasso += lasso.predict(\n        X_tr_enc.iloc[-len(X_original):]\n    ) / FOLDS\n\n    # ElasticNet\n    enet = ElasticNetCV(\n        l1_ratio=[0.2, 0.5, 0.8],\n        alphas=np.logspace(-4, 1, 20),\n        cv=5,\n        n_jobs=-1\n    )\n    enet.fit(X_tr_enc, y_tr_full)\n\n    oof_pred_enet[val] = enet.predict(X_val_enc)\n    test_preds_enet[:, fold-1] = enet.predict(X_test_enc)\n    orig_preds_enet += enet.predict(\n        X_tr_enc.iloc[-len(X_original):]\n    ) / FOLDS\n\n    rmse = np.sqrt(mean_squared_error(y_val, oof_pred_lr[val]))\n    print(f\"Fold {fold} | Ridge RMSE: {rmse:.5f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-01T14:58:55.399889Z","iopub.execute_input":"2026-02-01T14:58:55.400626Z"}},"outputs":[{"name":"stdout","text":"Fold 1 | Ridge RMSE: 8.84631\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"for col in base_features:\n    full_data[col] = full_data[col].astype(str).astype(\"category\")\n\nX_xgb = full_data.iloc[:len(train_df)].copy()\nX_test_xgb = full_data.iloc[len(train_df):len(train_df) + len(test_df)].copy()\nX_original_xgb = full_data.iloc[len(train_df) + len(test_df):].copy()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_xgb[\"ridge_pred\"] = oof_pred_lr\nX_xgb[\"lasso_pred\"] = oof_pred_lasso\nX_xgb[\"enet_pred\"]  = oof_pred_enet\n\nX_test_xgb[\"ridge_pred\"] = test_preds_lr.mean(axis=1)\nX_test_xgb[\"lasso_pred\"] = test_preds_lasso.mean(axis=1)\nX_test_xgb[\"enet_pred\"]  = test_preds_enet.mean(axis=1)\n\nX_original_xgb[\"ridge_pred\"] = orig_preds_lr\nX_original_xgb[\"lasso_pred\"] = orig_preds_lasso\nX_original_xgb[\"enet_pred\"]  = orig_preds_enet\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb_params = {\n    \"n_estimators\": 40000,\n    \"learning_rate\": 0.003,\n    \"max_depth\": 8,\n    \"subsample\": 0.82,\n    \"colsample_bytree\": 0.52,\n    \"colsample_bynode\": 0.68,\n    \"min_child_weight\": 7,\n    \"reg_lambda\": 8.0,\n    \"reg_alpha\": 0.3,\n    \"tree_method\": \"hist\",\n    \"enable_categorical\": True,\n    \"eval_metric\": \"rmse\",\n    \"random_state\": 42,\n    \"early_stopping_rounds\": 250,\n    \"device\": \"cuda\"\n}\n\noof_xgb = np.zeros(len(X_xgb))\ntest_preds_xgb = []\n\nfor fold, (tr, val) in enumerate(kf.split(X_xgb, y_bins), 1):\n\n    X_tr, X_val = X_xgb.iloc[tr], X_xgb.iloc[val]\n    y_tr, y_val = y.iloc[tr], y.iloc[val]\n\n    X_tr_full = pd.concat([X_tr, X_original_xgb])\n    y_tr_full = pd.concat([y_tr, y_orig])\n\n    model = xgb.XGBRegressor(**xgb_params)\n    model.fit(\n        X_tr_full, y_tr_full,\n        eval_set=[(X_val, y_val)],\n        verbose=False\n    )\n\n    oof_xgb[val] = model.predict(X_val)\n    test_preds_xgb.append(model.predict(X_test_xgb))\n\n    print(f\"Fold {fold} | XGB RMSE:\",\n          np.sqrt(mean_squared_error(y_val, oof_xgb[val])))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===== FINAL TEST PREDICTIONS =====\nfinal_test_pred = np.mean(test_preds_xgb, axis=0)\nfinal_test_pred = np.clip(final_test_pred, 0, 100)\n\n# ===== SUBMISSION FILE =====\nsubmission = pd.DataFrame({\n    \"id\": test_df[\"id\"],\n    TARGET: final_test_pred\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"submission.csv saved\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nplt.figure(figsize=(5,5))\nplt.scatter(y_val, final_test_pred, alpha=0.4)\nplt.plot([y_val.min(), y_val.max()],\n         [y_val.min(), y_val.max()],\n         color=\"red\")\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")\nplt.title(\"Actual vs Predicted (Validation)\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}